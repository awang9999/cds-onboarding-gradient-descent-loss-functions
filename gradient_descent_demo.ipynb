{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fc66306-b7a6-494c-9ac6-db5c9ffcb526",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gradient Descent and Loss Functions\n",
    "\n",
    "Authors: [Alexander Wang](https://github.com/awang9999), [Winnie Chow](https://github.com/winnie0617)\n",
    "\n",
    "<img src=\"images/header_picture.png\" width=300 height=200 />\n",
    "\n",
    "This module introduces the gradient descent algorithm for optimization and loss functions within the context of machine learning. This material is intended to be delivered on April 16, 2022 at a Cornell Data Science onboarding presentation, but is sufficient as standalone material as well.\n",
    "\n",
    "Topics covered:\n",
    "* Loss functions (MSE, MAE, Binary Cross Entropy, Hinge Loss)\n",
    "* Gradient Descent (general algorithm and intuition, proof of convergence omitted)\n",
    "* Gradient Descent variants (SGD, Mini-batched SGD)\n",
    "* Example of applying gradient descent to solve the optimization problem for multidimensional linear regression (using MSE loss).\n",
    "\n",
    "Associated slides for this presentation can be found [here](https://docs.google.com/presentation/d/1Er7sTuaL892dptan2unGSKmaC3BG7pKy8oNUIteFOhA/edit#slide=id.p)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a843a-22e4-4032-a507-e8eea877e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "# Require versions 3.7, 3.8 or 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583ad4fa-8027-4d12-8048-e3fbba49d416",
   "metadata": {},
   "source": [
    "## Part 1: Motivation\n",
    "\n",
    "Up until now “training” models have largely been a black box. We talk about it all the time, but how do we REALLY adjust the parameters of a model? What is a good measure for how well a model predicts the training data? How do we adjust the model parameters based on the model’s performance in predicting the training data automatically?\n",
    "\n",
    "This module aims to answer these questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7a327-f17a-4612-8041-3365a9c36830",
   "metadata": {},
   "source": [
    "## Part 2: Consider this problem\n",
    "\n",
    "For the rest of this module, we will work on solving a linear regression problem in higher dimensions (i.e. dim > 1). First we generate a noisy 2 dimensional linearly distributed dataset. (I.e. it can be modeled by a plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f29c6-de29-4cc4-a8b6-8d1db506b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29db09a-9211-4e5c-b5e5-00aa2c357fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True target function\n",
    "def f(x1, x2):\n",
    "    return 0.15*x1 + 0.3*x2 + 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0520ceb4-4284-48de-8bbe-c316f55aca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n):\n",
    "    Xs = np.zeros((n,2))\n",
    "    # Uniformly random selection of points within [0,100]x[0,100]\n",
    "    Xs[:,0] = np.random.uniform(-10, 10, n)\n",
    "    Xs[:,1] = np.random.uniform(-10, 10, n)\n",
    "    \n",
    "    # Noise added to true target function\n",
    "    ydelta = np.random.uniform(-1, 1, n)\n",
    "    \n",
    "    Ys = f(Xs[:,0], Xs[:,1]) + ydelta\n",
    "    \n",
    "    return Xs, Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f87c34-1d47-4a5a-8f26-df997991df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs, Ys = generate_data(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330bb80a-c7a6-4e13-8813-d4fca170a332",
   "metadata": {},
   "source": [
    "We can visualize our dataset using a 3D plot. Indeed, it can be modelled by a plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a996575c-7f5f-4d14-9952-7cf513a339c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(Xs[:,0], Xs[:,1], Ys, c='green')\n",
    "\n",
    "x = np.linspace(-10, 10, 10)\n",
    "y = np.linspace(-10, 10, 10)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = f(X, Y)\n",
    "\n",
    "ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='Blues', edgecolor='none', alpha=0.4)\n",
    "\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_zlabel('y');\n",
    "ax.view_init(30, -30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ac6ac3-0357-4184-8442-8b5590a03a07",
   "metadata": {},
   "source": [
    "### Part 2.1: Vector Calculus Review\n",
    "\n",
    "The equation of a plane is given by\n",
    "\n",
    "$$h(x_1, x_2) = w_1x_1 + w_2x_2 + b$$\n",
    "\n",
    "where $w_1, w_2$ are the coefficients of the $x_1$ and $x_2$ variables respectively. $b$ can be thought of as the offset.\n",
    "We can rewrite this in vector form as\n",
    "\n",
    "$$ h(x) = \\begin{bmatrix}w_1 & w_2\\end{bmatrix} \\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix} + b = w^Tx + b$$\n",
    "\n",
    "Note that vectors are conventionally column vectors in mathematics. This equation gives us a model for which we want to train for our particular dataset. In other words, can we recover $w$ and $b$ such that the plane \"best\" fits the generated dataset automatically? How can we define \"best\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfc8d8c-3e8e-453e-8334-816705668fce",
   "metadata": {},
   "source": [
    "## Part 3: Loss Functions\n",
    "\n",
    "Loss functions compare a model's predictions to the true values given by the training dataset. They measure how much the predicted $y$ deviates from the true $y$ for all examples in the training dataset. For regression problems, the loss is usually some sort of aggregate error. For classification problems, the loss is usually some aggregate of misclassifications. We introduce a couple loss functions below:\n",
    "\n",
    "#### Mean Squared Error (MSE)\n",
    "$$\\mathcal{L}(h,X,Y) = \\frac{1}{n}\\sum_{i=1}^n(h(x_i) - y_i)^2$$\n",
    "* This loss is usually used for regression tasks.\n",
    "* This loss function is differentiable everywhere.\n",
    "* [link to wikipedia](https://en.wikipedia.org/wiki/Mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6372d86-9823-4158-85c3-692ab54bb0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_loss(h, X, Y):\n",
    "    n = len(Y)\n",
    "    loss = 1.0/n * sum((h(X) - Y)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d02a7c5-6b9a-4b74-a30f-e520644ec949",
   "metadata": {},
   "source": [
    "#### Mean Absolute Error (MAE)\n",
    "$$\\mathcal{L}(h,X,Y) = \\frac{1}{n}\\sum_{i=1}^n|h(x_i) - y_i|$$\n",
    "* This loss is usually used for regression tasks.\n",
    "* This loss function is not differentiable at 0.\n",
    "* [link to wikipedia](https://en.wikipedia.org/wiki/Mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e02cd18-05df-48ab-a10b-35dcc4a0545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE_loss(h, X, Y):\n",
    "    n = len(Y)\n",
    "    loss = 1.0/n * np.sum(np.abs(h(X) - Y))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289bda00-8bff-4ad5-9504-f62c62d9cb68",
   "metadata": {},
   "source": [
    "#### Hinge Loss\n",
    "$$\\mathcal{L}(h,X,Y) = \\frac{1}{n}\\sum_{i=1}^n \\max(0, 1-y_i h(x_i))$$\n",
    "* This loss is usually used for classification tasks.\n",
    "* This loss function is not differentiable at 0.\n",
    "* [link to wikipedia](https://en.wikipedia.org/wiki/Hinge_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b744da4c-7809-4689-9851-2d02409a5ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss(h, X, Y):\n",
    "    n = len(Y)\n",
    "    loss = 1.0/n * np.sum(np.max(0,1- Y*h(X)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3047e6db-ab0d-4bc8-ab8d-20dba7b9d5a4",
   "metadata": {},
   "source": [
    "#### Binary Cross Entropy\n",
    "$$\\mathcal{L}(h,X,Y) = -\\frac{1}{n}\\sum_{i=1}^n (y_i\\log(h(x)) + (1-y_i)\\log(1-h(x))$$\n",
    "* This loss is usually used for classification tasks\n",
    "* This loss function is differentiable everywhere in its domain.\n",
    "* $h(x)$ in this case returns a probability rather than an absolute class. (Specifically $h(x) = P(y=+1|x)$)\n",
    "* [link to wikipedia](https://en.wikipedia.org/wiki/Cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d7b5ba-994c-421f-a7c3-cb02a0eb387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCE_loss(h, X, Y):\n",
    "    n = len(Y)\n",
    "    loss = -1.0/n * np.sum(Y*np.log(h(X)) + (1-Y)*np.log(1-h(X)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cd130e-70c0-4336-8da7-cdcc82658a83",
   "metadata": {},
   "source": [
    "These loss functions are just a small selection of the commonly used ones. Each loss function has advantages and disadvantages, for which wikipedia provides a much more rigorous treatment. Now we have established a few methods to evaluate the quality of a model on the training dataset. A lower loss for a particular model implies that model fits the training dataset better. (I.e. the performance of a model is inversely proportional to its loss.) How can we use these metrics to recover the optimal $w$ and $b$ in our problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e53697f-3dae-44bf-8f66-58455768b005",
   "metadata": {},
   "source": [
    "## Part 4: Regression\n",
    "You may recognize this as a multidimensional linear regression problem: given $X$s and $Y$s, find $w$ and $b$ such that $h(x) = wx + b$ best models the dataset $(X,Y)$. The convention for this problem is to use mean squared error (MSE) as a loss function. We formulate the following criterion, for which we want to optimize (I.e. find the minimum):\n",
    "\n",
    "$$\\begin{align*}\n",
    "    \\arg\\min_{w,b} \\mathcal{L}(w,b) &= \\arg\\min_{w,b} \\frac{1}{2n}\\sum_{i=1}^n((w^Tx_i + b) - y_i)^2 \\\\\n",
    "    &= \\arg\\min_{w,b} \\frac{1}{2n}(\\dot{X}(b \\; w)-Y)^T(\\dot{X}(b \\; w)-Y) \\\\\n",
    "    &= \\arg\\min_{\\theta} \\frac{1}{2n} (\\dot{X}\\theta-Y)^T(\\dot{X}\\theta-Y)\n",
    "\\end{align*}$$\n",
    "where $\\theta = (b \\; w)$, $\\dot{x}_i = (1 \\; x_i)^T$ and $\\dot{X}$ is produced analogously.\n",
    "\n",
    "There exists an analytical solution for the optimal $w$ and $b$, that is:\n",
    "\n",
    "$$\\theta^* = (\\dot{X}^T \\dot{X})^{-1}\\dot{X}^T Y$$\n",
    "\n",
    "$$w^* = \\theta^*[1:]$$\n",
    "\n",
    "$$b^* = \\theta^*[0]$$\n",
    "\n",
    "where $\\bar{x}$ and $\\bar{y}$ represents the mean value of $X$ and $Y$ respectively. (The derivation for this solution is outside the scope of this discussion, but contact the authors if you're interested! [reference](https://towardsdatascience.com/analytical-solution-of-linear-regression-a0e870b038d5))\n",
    "\n",
    "Although there is a closed form analytical solution to optimizing our model (multidimensional linear regression) this is RARELY the case in practice. Most models do not have a closed form analytical solution. Moreover, computing the analytical solution may be slow (if it is even possible) especially for more complicated problems. Nevertheless, we write code to compute the analytical solution to produce a \"target\" for the iterative methods introduced below, that is, gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af2cb38-a061-4b2f-ac4a-14dad0d3f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "n = len(Ys)\n",
    "zeros = np.ones((n, 1))\n",
    "Xdots = np.hstack((zeros,Xs))\n",
    "\n",
    "def multidim_linear_regression(X, Y):\n",
    "    theta = inv(X.T @ X) @ (X.T @ Y)\n",
    "    \n",
    "    w = theta[1:]\n",
    "    b = theta[0]\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38302689-983a-4da2-963e-b9548bd6808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_analytical, b_analytical = multidim_linear_regression(Xdots, Ys)\n",
    "print(f'The analytical regression solution is h(x) = {w_analytical}^T * x + ({b_analytical}).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14490cd-b43e-4a10-b6c5-967ae9bec623",
   "metadata": {},
   "source": [
    "## Part 5: Gradient Descent\n",
    "\n",
    "So how can we find the minimum of a function? If we recall from calculus, there exist analytical methods to do so...(set derivative equal zero and solve derivatives for optimization variables, lagrange multipliers, etc). In practice, these methods rarely work because some functions cannot be solved analytically (ex. $x^4 + x^5 + x^6 + log(x + x^5) = 0$).\n",
    "\n",
    "We can use an iterative method to approximate local minima: gradient descent. Recall that the gradient of a function is the direction of steepest ascent (proven in multivariable calculus). What if we start from a random point and move slightly in the direction of steepest descent?\n",
    "\n",
    "### Gradient Descent Algorithm\n",
    "\n",
    "Given a loss function $\\mathcal{L}$, a parameter to optimize $w$, a maximum number of iterations $T$, and a step size $\\eta_t$ (allowed to depend on $t$, will be discussed later), we give the following algorithm for optimizing $w$:\n",
    "\n",
    "Initialize $w^{(0)} = (0,...,0)$.\n",
    "\n",
    "For $t = 1, 2, 3, ..., T$:\n",
    "\n",
    "$$w^{(t+1)} \\leftarrow w^{(t)} - \\eta_t \\nabla \\mathcal{L}(w^{(t)})$$\n",
    "\n",
    "Output $w^{(T)}$.\n",
    "\n",
    "<img src=\"images/gd_animation.gif\" width=512 height=384 />\n",
    "\n",
    "Here, we give an implementation of gradient descent and apply it to solve our problem. Recall the loss function of our problem after wrapping $w$ and $b$ into a single parameters variable $\\theta$:\n",
    "\n",
    "$$ \\mathcal{L}(\\theta) = \\frac{1}{2n} (\\dot{X}\\theta-Y)^T(\\dot{X}\\theta-Y) $$\n",
    "\n",
    "The gradient of this loss function is:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}(\\theta)}{\\partial \\theta} = \\frac{1}{n}(\\dot{X}^T\\dot{X} \\theta - \\dot{X}^TY)$$\n",
    "\n",
    "(derivation omitted). Then we can write the code for gradient descent in our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3173fb6b-596d-4a29-861c-20e5b06c0efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(theta, X, Y):\n",
    "    n = len(Y)\n",
    "    X_theta = X @ theta\n",
    "    X_theta_minus_Y = X_theta - Y\n",
    "    \n",
    "    loss = 1/(2.0*n) * ((X_theta_minus_Y).T @ X_theta_minus_Y)\n",
    "    grad = 1.0/n * (X.T @ (X_theta) - (X.T @ Y)) \n",
    "    \n",
    "    return loss, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d8f4c7-2cf2-4e8f-b850-b49818d053f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(func, X, Y, max_iter=2000, lr=0.001, delta=1e-02):\n",
    "    \n",
    "    d = len(X[0])\n",
    "    \n",
    "    losses = np.zeros(max_iter)\n",
    "    grad = np.zeros(d)\n",
    "    theta = np.random.rand(d)\n",
    "    \n",
    "    for t in range(max_iter):\n",
    "        losses[t], grad = func(theta, X, Y)\n",
    "        theta -= lr * grad\n",
    "        if np.linalg.norm(grad) < delta:\n",
    "            print('converged before max_iters')\n",
    "            losses = losses[:t+1]\n",
    "            break\n",
    "    \n",
    "    w_opt = theta[1:]\n",
    "    b_opt = theta[0]\n",
    "    \n",
    "    return losses, w_opt, b_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930d9463-caf5-4102-b447-5a4ef8725d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_gd, w_gd, b_gd = gradient_descent(least_squares, Xdots, Ys)\n",
    "print(f'The gradient descent solution is h(x) = {w_gd}^T * x + ({b_gd}) with \\n loss {losses_gd[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f723b9-b8ae-467e-adca-68799d0014f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = range(len(losses_gd))\n",
    "plt.plot(iters, losses_gd)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0724427-611b-47e7-b433-4540237ecb29",
   "metadata": {},
   "source": [
    "We see that the recovered function is close to the generating function $f(x) = 0.15x_1 + 0.3x_2 + 0.2$ with a bit of noise which is what we expect since the data does is not exactly linear. Also notice that the final loss of gradient descent is not too far off of the loss produced by the analytically optimal parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f7327b-c2fc-4c72-b2fa-7610b0556620",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, _ = least_squares([b_analytical, w_analytical[0], w_analytical[1]], Xdots, Ys)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55ae206-cf85-4614-9c32-65eb4686d783",
   "metadata": {},
   "source": [
    "As good as gradient descent is, there are still numerous potential issues with it in its current form:\n",
    "* It might not find the global minimum\n",
    "    * It can get stuck in a local minimum    \n",
    "    * It might keep overshooting the minimum if $\\eta_t$ is too large.\n",
    "* Non-deterministic (starting point is arbitrary/random)\n",
    "* Computationally expensive for large datasets\n",
    "* Takes many iterations to converge (if at all)\n",
    "\n",
    "<img src=\"images/local_minima.png\" width=212 height=166 />\n",
    "\n",
    "<img src=\"images/overshooting.png\" width=600 height=150 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78382889-51e9-4abe-9d90-a9af46ab84df",
   "metadata": {},
   "source": [
    "## Part 6: Variations of Gradient Descent\n",
    "\n",
    "One of the pitfalls of gradient descent is the computational cost of running it on large datasets. For each iteration, we compute the gradient of each training example and take the average. What if we only computed the gradient of one training example at each step?\n",
    "\n",
    "#### Stochastic Gradient Descent (SGD)\n",
    "\n",
    "Initialize $w^{(0)} = (0,...,0)$.\n",
    "\n",
    "For $t = 1, 2, 3, ..., T$:\n",
    "\n",
    "Choose $x_i, y_i$ randomly among $X, Y$.\n",
    "\n",
    "$$w^{(t+1)} \\leftarrow w^{(t)} - \\eta_t \\nabla \\mathcal{L}(w^{(t)}, x_i, y_i)$$\n",
    "\n",
    "Output $w^{(T)}$.\n",
    "\n",
    "This algorithm leverages the fact that we can evaluate the loss only at one randomly chosen example to get an estimate of the real loss. Then, the expectation of the gradient (only evaluated at one element) among many iterations is, roughly speaking, the real gradient.\n",
    "\n",
    "* Advantage: Evaluate loss function  only on one sample\n",
    "* Advantage: Much more efficient, and might help overcome local minima\n",
    "* Disadvantage: Might take (many) more iterations / does not converge at all\n",
    "\n",
    "<img src=\"images/sgd_animation.gif\" width=512 height=384 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd6fa74-3699-41d8-83da-3f3660bb542c",
   "metadata": {},
   "source": [
    "#### Mini-Batch Gradient Descent\n",
    "\n",
    "Initialize $w^{(0)} = (0,...,0)$.\n",
    "\n",
    "For $t = 1, 2, 3, ..., T$:\n",
    "\n",
    "Choose $X_{batch}, Y_{batch}$, a subset of $X, Y$, randomly.\n",
    "\n",
    "$$w^{(t+1)} \\leftarrow w^{(t)} - \\eta_t \\nabla \\mathcal{L}(w^{(t)}, X_{batch}, Y_{batch})$$\n",
    "\n",
    "Output $w^{(T)}$.\n",
    "\n",
    "Similar to SGD, mini-batched gradient descent only evaluates the loss for a (small) subset of the total examples.\n",
    "\n",
    "* Advantage: Evaluate loss function on a subset of samples.\n",
    "* Mid-vantage: The medium between SGD and pure gradient descent, effectively the best of both worlds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3352d8f0-ee47-42d9-a815-db1bde4d4e1d",
   "metadata": {},
   "source": [
    "#### Adagrad\n",
    "\n",
    "Given step size parameter $\\alpha > 0$, tolerance $\\delta > 0$ and a small number $\\epsilon > 0$:\n",
    "\n",
    "Initialize $w = (0,...,0)$ and $z = (0,...,0)$.\n",
    "\n",
    "Repeat until converged:\n",
    "\n",
    "$ g = \\nabla \\mathcal{L}(w^{(t)})$ # compute gradient\n",
    "\n",
    "for all $i \\in {1, ..., d}$, set $z_d \\leftarrow z_d + g_d^2$\n",
    "\n",
    "for all $i \\in {1, ..., d}$, update $w_d \\leftarrow w_d - \\alpha \\frac{g_d}{\\sqrt{z_d + \\epsilon}}$\n",
    "\n",
    "If $\\|w^{(t+1)} - w^{(t)}\\| \\leq \\delta$, converged!\n",
    "\n",
    "Output $w$.\n",
    "\n",
    "This algorithm works the same as gradient descent except it sets the learning rate adaptively for every feature.\n",
    "\n",
    "* Advantage: adaptive gradients for each feature\n",
    "* Advantage: high learning rate for features with small gradients, low learning rates for features with large gradients. \n",
    "* Disadvantage: Still computes gradient for every example\n",
    "* Disadvantage: Introduces additional computations on the order of magnitude of the dimensions of the problem.\n",
    "\n",
    "Adagrad works very well in practice, so we include an implementation of it for our regression problem. Feel free to reference back to this if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e57eb3-6307-435d-a668-43c04e6c88b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adagrad(func, alpha, X, Y, maxiter=1000,delta=1e-02):\n",
    "    d = len(X[0])\n",
    "    \n",
    "    losses = np.zeros(maxiter)\n",
    "    eps = 1e-06\n",
    "    \n",
    "    theta = np.random.rand(d)\n",
    "    grad = np.zeros(d)\n",
    "    z = np.zeros(d)\n",
    "    \n",
    "    for i in range(maxiter):\n",
    "        losses[i], grad = func(theta, X, Y)\n",
    "        #print(losses[i])\n",
    "        z += grad ** 2\n",
    "        theta -= alpha * grad / np.sqrt(z + eps)\n",
    "        if np.linalg.norm(grad) < delta: \n",
    "            losses = losses[:i+1]\n",
    "            break\n",
    "    \n",
    "    w_opt = theta[1:]\n",
    "    b_opt = theta[0]\n",
    "    \n",
    "    return losses, w_opt, b_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3762d21-cbd9-4820-86db-3fb24a6a2748",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_ada, w_ada, b_ada = adagrad(least_squares, 1, Xdots, Ys)\n",
    "print(f'The gradient descent solution is h(x) = {w_ada}^T * x + ({b_ada}) with \\n loss {losses_ada[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94b503b-2189-4ee0-bcd2-25eb3b4afeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = range(len(losses_ada)-1)\n",
    "plt.plot(iters, losses_ada[1:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb85d7c-7020-4dbf-933e-da6f3b937e32",
   "metadata": {},
   "source": [
    "Here is a visualization for the rate of convergence for SGD, Momentum, RMSProp, and Adam (all additional gradient descent variants) from the Intelligent Systems subteam onboarding materials:\n",
    "* Enter root folder of this project\n",
    "* Enter interactive_gd\n",
    "* Open variants_visual.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b565534-5377-4ad2-a991-03ec4fc8cc34",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* https://towardsdatascience.com/analytical-solution-of-linear-regression-a0e870b038d5\n",
    "* https://www.cs.cornell.edu/courses/cs4780/2022sp/notes/LectureNotes11.html\n",
    "* https://www.cs.cornell.edu/courses/cs4780/2022sp/notes/LectureNotes12.html\n",
    "* https://www.cs.cornell.edu/courses/cs4780/2022sp/notes/LectureNotes14.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdvenv",
   "language": "python",
   "name": "gdvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
