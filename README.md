# cds-onboarding-gradient-descent-loss-functions

Authors: [Alexander Wang](https://github.com/awang9999), [Winnie Chow](https://github.com/winnie0617)

This repository contains introductory material about the gradient descent algorithm for optimization and loss functions within the context of machine learning. This material is intended to be delivered on April 16, 2022 at a Cornell Data Science onboarding presentation, but is sufficient as standalone material as well.

Topics covered:
* Loss functions (MSE, MAE, Binary Cross Entropy, Hinge Loss)
* Gradient Descent (general algorithm and intuition, proof of convergence omitted)
* Gradient Descent variants (SGD, Mini-batched SGD)
* Brief discussion on Newton's method
* Example of applying gradient descent to solve the optimization problem for multidimensional linear regression (using MSE loss).

Associated slides for this presentation can be found [here](https://docs.google.com/presentation/d/1Er7sTuaL892dptan2unGSKmaC3BG7pKy8oNUIteFOhA/edit#slide=id.p).

